{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gcorrigan/Science-des-donnees/blob/main/Science_des_donn%C3%A9es_Partie_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R86feJrF5vZE"
      },
      "source": [
        "# La science des données- Partie 2\n",
        "### Introduction au génie informatique, 11e année, cours préuniversitaire (ICS3U)\n",
        "\n",
        "# Description générale du cours\n",
        "> Ce cours initie l’élève aux concepts fondamentaux de l’informatique et aux techniques de développement de logiciels. Dans le cadre de divers projets illustrant le cycle de vie d’un logiciel, l’élève développe des habiletés et une compréhension solide d’un langage de programmation en se familiarisant avec les outils et les techniques de développement de logiciels, notamment la résolution de problèmes, la conception d’algorithmes et l’assurance-qualité.\n",
        "\n",
        "[Études informatiques (2008)](https://www.edu.gov.on.ca/fre/curriculum/secondary/computer10to12_2008fr.pdf#page=49)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtRoiyrw5vZE"
      },
      "source": [
        "### La science des données en 3 parties\n",
        "\n",
        "Partie 1 : Nous examinons les structures de données de base de Python ainsi que quelques visualisations simples.\n",
        "\n",
        "**Partie 2 : Nous explorons et apprenons à utiliser plus en profondeur les outils de science des données dédiés de Python.**\n",
        "\n",
        "Partie 3 : Nous appliquons nos connaissances à un projet comportant plusieurs étapes et visualisations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dT2lLvly5vZF"
      },
      "source": [
        "#Programme\n",
        "\n",
        "*   Apprendre à utiliser les outils de science des données dédiés de Python.\n",
        "*   Représenter les données en choisissant les bonnes structures et étiquettes pour un ensemble de données.\n",
        "*   Analyser les données en transformant, sélectionnant et calculant des statistiques sur les données.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Les objectifs d’apprentissage\n",
        "\n",
        "*   Démontrer la capacité d'utiliser différents types de données, y compris des tableaux unidimensionnels, dans les programmes informatiques.\n",
        "\n",
        "*   Démontrer la capacité d'utiliser des structures de contrôle et des algorithmes simples dans les programmes informatiques.\n"
      ],
      "metadata": {
        "id": "pDiKGPntlPH4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Les critères de réussite\n",
        "*   Je peux choisir et implémenter une structure pour représenter un ensemble de données en code.\n",
        "*   Je peux manipuler une structure de données en code pour sélectionner, organiser et analyser les données."
      ],
      "metadata": {
        "id": "LiGupj4VlaGR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_tDUUXU5vZF"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "La **science des données** peut sembler être un sujet complexe, mais en réalité, cela se résume à ceci :\n",
        "\n",
        "> Il y a une tonne de données là-bas ! Comment trouver l'information que je cherche ? Comment la comprendre ? Et comment la rendre pertinente ?\n",
        "\n",
        "En d'autres termes, la science des données est la science de la manipulation des données afin de *répondre à une question spécifique*.\n",
        "\n",
        "Python nous permet de le faire en nous fournissant des outils pour représenter les données, les manipuler ou les sélectionner, les analyser, et créer des graphiques, des cartes, des tableaux et d'autres visualisations qui les affichent. Dans ce notebook, nous apprenons à utiliser ces outils. (Dans le prochain notebook, nous examinerons de plus près la collecte et le nettoyage de données provenant de différentes sources réelles afin que nous puissions mettre nos compétences en pratique pour un objectif spécifique.)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1221iB75vZF"
      },
      "source": [
        "## 1. Représentation des données\n",
        "\n",
        "Comme nous l'avons vu dans la partie 1, la plus grande puissance de Python vient souvent de l'utilisation de bibliothèques externes. Deux bibliothèques de base pour la science des données sont `numpy` (*Numerical Python*) et `pandas` (*Python for Data Analysis*).\n",
        "\n",
        "Nous allons nous concentrer sur `pandas` pour cette leçon afin de simplifier les choses. (Cependant, notez que `pandas` est en fait construit sur `numpy`, et utilise les types de données `numpy` tels qu'un `ndarray` au lieu de `list` intégrée de Python.)\n",
        "\n",
        "Exécutez ce bloc de code pour vous assurer que vous avez pandas installé :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqVPnVW75vZF"
      },
      "outputs": [],
      "source": [
        "# Installez numpy et pandas dans l'environnement actuel. Pandas installera automatiquement numpy car c'est une dépendance.\n",
        "\n",
        "%pip install pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHSk_Dwi5vZG"
      },
      "source": [
        "Ensuite, exécutez ce bloc pour l'importer. N'oubliez pas que dans les notebooks Jupyter, toutes les cellules partagent un pool de mémoire, donc si nous l'importons au début, elles seront disponibles pour tous les blocs futurs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GFDSSziO5vZG"
      },
      "outputs": [],
      "source": [
        "# Import pandas\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPt8hRvZ5vZG"
      },
      "source": [
        "### Une série (*Series*)\n",
        "\n",
        "Il y a deux structures de données de base dans `pandas`: `Series` et `DataFrame`.\n",
        "\n",
        "Une `Series` est avant tout un tableau à une dimension, comme une  `list`. \n",
        "\n",
        "Exécutez ce bloc de code pour voir un exemple."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMyg2Yqn5vZH"
      },
      "outputs": [],
      "source": [
        "# Une série (Series) représentant des données aléatoires.\n",
        "s = pd.Series([200, 210, 215, 230, 291])\n",
        "print(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnF2clZO5vZH"
      },
      "source": [
        "#### Qu'est-ce qui rend une `Series` unique?\n",
        "\n",
        "Cette sortie est un peu surprenante pour un tableau à une dimension! Nous remarquons qu'elle est présentée comme un tableau, avec une colonne pour l'index et une autre pour les données.\n",
        "\n",
        "Cela nous donne un indice sur la première qualité unique d'une `Series`: vous pouvez utiliser n'importe quel type d'index, pas seulement un décompte numérique à partir de `0`.\n",
        "\n",
        "Essayons de créer un index personnalisé. Exécutez ce bloc de code. Pouvez-vous deviner ce que représentent ces données?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXXf6p4y5vZH"
      },
      "outputs": [],
      "source": [
        "# Utilisation de chaînes de caractères pour l'index.\n",
        "s = pd.Series([200, 210, 215, 230, 291],\n",
        "              index=['Skor', 'Heath', 'Snickers', 'Mars', 'Twix'])\n",
        "print(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2nhiAaF5vZH"
      },
      "source": [
        "Dans le code ci-dessus, chaque  rangée du tableau a été nommée. Vous pourriez penser maintenant que c'est comme un dictionnaire, avec des paires clé-valeur, et c'est une observation valide."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrryNHcg5vZH"
      },
      "source": [
        "**Vérification de compréhension :** Remarquez que nous avons le même nombre de valeurs et d'étiquettes. Et si ces deux listes avaient des longueurs différentes? Faites une supposition, puis essayez-le."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YP8W4Bk05vZH"
      },
      "source": [
        "De plus, il y a quelque chose d'étrange à la fin de notre sortie de `series`: un `dtype int64`! Ce type de données est répertorié car une `series` ne peut contenir qu'un seul type de données pour tous ses éléments. C'est l'un des principes clés d'avoir des ensembles de données propres: une restriction comme celle-ci nous aide à éviter de comparer des pommes et des oranges, ou plutôt 5 nombres et des oranges.\n",
        "\n",
        "Dans ce cas, `pandas` a deviné le type de données que nous voulions, un entier de 64 bits. C'est une supposition très généreuse car la valeur maximale d'un `int64` est de 2^64, soit environ 9 quintillions. Nous pouvons optimiser notre `series` en spécifiant le type de données si nous connaissons les limites de notre ensemble de données. Utilisons `int16`, ce qui nous donne une surcharge de 2^16 ou 65 536."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbEdXs6O5vZH"
      },
      "outputs": [],
      "source": [
        "# Spécifier un type de données\n",
        "s = pd.Series([200, 210, 215, 230, 291],\n",
        "              index=['Skor', 'Heath', 'Snickers', 'Mars', 'Twix'],\n",
        "              dtype='int16')\n",
        "print(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdzNEHzI5vZI"
      },
      "source": [
        "**Vérification de compréhension :**Que se passerait-il si vous utilisiez un type de données encore plus petit, comme `int8`? Faites une supposition, puis essayez-le."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27qsutjb5vZI"
      },
      "source": [
        "Voici une [référence complète](https://pandas.pydata.org/docs/reference/api/pandas.Series.html) de `pandas.Series`. Nous allons examiner quelques tâches courantes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8a4Kxgsy5vZI"
      },
      "outputs": [],
      "source": [
        "# Obtenez toutes les valeurs\n",
        "s.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTXhqy345vZI"
      },
      "outputs": [],
      "source": [
        "# Obtenez un élément spécifique\n",
        "s.loc['Skor']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPCk4dlA5vZI"
      },
      "outputs": [],
      "source": [
        "# Obtenez la longueur de la série\n",
        "s.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xk-yWMoB5vZI"
      },
      "outputs": [],
      "source": [
        "# Obtenez la valeur la plus élevée de la série\n",
        "s.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXQxMmFN5vZI"
      },
      "outputs": [],
      "source": [
        "# Obtenez la valeur la plus basse de la série\n",
        "s.min()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocOj7q0T5vZI"
      },
      "source": [
        "# Les exemples ci-dessous montrent des fonctionnalités de `Pandas` qui sont supérieures à une simple liste Python. Nous avons vu dans les exemples ci-dessus comment trouver les valeurs maximales et minimales de la série ; et si nous voulons savoir quelles barres de chocolat correspondent aux valeurs maximales et minimales ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CKKnCaX5vZJ"
      },
      "outputs": [],
      "source": [
        "# Obtenez le nom de la barre de chocolat avec la valeur la plus élevée\n",
        "s.idxmax()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCqJ3dJZ5vZJ"
      },
      "outputs": [],
      "source": [
        "# Obtenez le nom de la barre de chocolat avec la valeur la plus basse\n",
        "s.idxmin()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ar2XLi95vZJ"
      },
      "source": [
        "Nous pouvons également trier une `Series` par [ses valeurs](https://pandas.pydata.org/docs/reference/api/pandas.Series.sort_values.html) ou par ses [indices](https://pandas.pydata.org/docs/reference/api/pandas.Series.sort_index.html). (Notez que contrairement à une liste, cela n'est pas fait en place à moins que vous ne spécifiiez l'argument mot-clé `inplace=True`.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqMFZ3Cn5vZJ"
      },
      "outputs": [],
      "source": [
        "# Trier une série par valeur\n",
        "print(s.sort_values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mYSawek5vZJ"
      },
      "outputs": [],
      "source": [
        "# Trier une série par index\n",
        "print(s.sort_index())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rywn1Hd-5vZJ"
      },
      "source": [
        "Nous pouvons également effectuer des opérations très utiles sur l'ensemble de la `Series`. La `list` de Python peut-elle faire cela?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWqpBjjB5vZJ"
      },
      "outputs": [],
      "source": [
        "# Ajouter à tous les éléments de la série\n",
        "s = s + 100\n",
        "print(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bx3K3PZO5vZJ"
      },
      "outputs": [],
      "source": [
        "# Multiplier tous les éléments de la série\n",
        "s = s * 5\n",
        "print(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POGGqi-L5vZK"
      },
      "source": [
        "En fait, nous pouvons exécuter n'importe quelle fonction sur tous les éléments d'une `Series`. Obtenons la racine carrée de chaque valeur :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHJbxatd5vZK"
      },
      "outputs": [],
      "source": [
        "# Trouver les racines carrées\n",
        "from math import sqrt\n",
        "s = s.map(sqrt)\n",
        "print(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O1ZvOHr5vZK"
      },
      "source": [
        "Ces décimales ne sont pas très jolies. Arrondissons-les à 2 décimales :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyFnGxg_5vZK"
      },
      "outputs": [],
      "source": [
        "# Arrondir tous les éléments de la série\n",
        "s = s.round(2)\n",
        "print(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t49EAeAz5vZK"
      },
      "source": [
        "**Vérification de compréhension :** Explorez quelques opérations supplémentaires sur cette `Series` : c'est-à-dire la soustraction, la division, l'exponentiation, la négation.\n",
        "\n",
        "Exécutez ce bloc pour réinitialiser votre `Series` :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hxlva_Ok5vZK"
      },
      "outputs": [],
      "source": [
        "s = pd.Series([200, 210, 215, 230, 291],\n",
        "              index=['Skor', 'Heath', 'Snickers', 'Mars', 'Twix'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ega08dj85vZK"
      },
      "source": [
        "Nous pouvons faire beaucoup plus avec une `Series`, notamment :\n",
        "\n",
        "* Filtrage des données\n",
        "* Corréler les données\n",
        "* Analyser des données (par exemple des moyennes)\n",
        "\n",
        "Nous les conserverons pour la section suivante."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nM7lBSzr5vZK"
      },
      "source": [
        "### Un tableau de données Pandas (*DataFrame*)\n",
        "\n",
        "Voici l'autre structure majeure de `pandas`. Une fois que nous comprenons une `Series`, un `DataFrame` n'est pas trop compliqué : c'est simplement un ensemble de `Series` collées ensemble dans un tableau. En d'autres termes, c'est bidimensionnel.\n",
        "\n",
        "Voici une [référence complète](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) de `pandas.DataFrame`. Nous allons examiner quelques tâches courantes.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Commençons par simplement passer notre `Series` existante dans un `DataFrame`. Lorsque nous le ferons, nous lui donnerons un nom, donc je vais maintenant révéler ce que ces valeurs représentent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LC7SlBbd5vZK"
      },
      "outputs": [],
      "source": [
        "# Création d'un DataFrame à partir d'une Série.\n",
        "s = pd.Series([200, 210, 215, 230, 291],\n",
        "              index=['Skor', 'Heath', 'Snickers', 'Mars', 'Twix'],\n",
        "              name='Calories par paquet')\n",
        "\n",
        "df = pd.DataFrame(s)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQciXXB45vZL"
      },
      "source": [
        "Nous pouvons maintenant ajouter une autre `Series` et agrandir notre tableau.\n",
        "\n",
        "Notez que nous n'avons pas besoin de nommer notre nouvelle `Series` car le `DataFrame` a besoin d'un nom de colonne de toute façon. Nous devons nous assurer que les indices correspondent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3rYzky15vZL"
      },
      "outputs": [],
      "source": [
        "# Ajouter une autre série à un DataFrame\n",
        "s2 = pd.Series([39, 39, 44, 51, 58],\n",
        "               index=['Skor', 'Heath', 'Snickers', 'Mars', 'Twix'])\n",
        "\n",
        "df['Grammes par paquet'] = s2\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hOag31T5vZL"
      },
      "source": [
        "Voilà! Maintenant, cela ressemble davantage à un tableau.\n",
        "\n",
        "**Vérification de compréhension :** Pouvez-vous ajouter une colonne avec les valeurs du niveau de délice pour chaque barre sur une échelle de 1 à 10 ?  (Vous pouvez inventer les valeurs, mais Mars est définitivement plus délicieuse que Snickers.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9ZdxJXf5vZL"
      },
      "outputs": [],
      "source": [
        "# Ajouter une troisième colonne 'Délicieuseté'\n",
        "s3 = pd.Series([5, 5, 6, 8, 3],\n",
        "               index=['Skor', 'Heath', 'Snickers', 'Mars', 'Twix'])\n",
        "\n",
        "df['Délicieuseté'] = s3\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksO_oflQ5vZL"
      },
      "source": [
        "#### Quelques autres façons de créer des `DataFrame`\n",
        "\n",
        "Dans l'exemple ci-dessus, nous avons créé un `DataFrame` à partir d'une `Series`, mais nous pouvons également en créer un à partir de rien comme celui-ci."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ot-jaqCP5vZL"
      },
      "outputs": [],
      "source": [
        "# Faire un DataFrame sans d'abord faire une série\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'Calories par paquet'  : [200, 210, 215, 230, 291],\n",
        "    'Grammes par paquet'     : [39, 39, 44, 51, 58],\n",
        "    'Délicieuseté'         : [5, 4, 8, 6, 2]\n",
        "}, index=['Skor', 'Heath', 'Snickers', 'Mars', 'Twix'])\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQV6fGKS5vZL"
      },
      "source": [
        "Une autre façon – et tout aussi bonne – de représenter ces données serait de prendre le nom de la barre de chocolat comme colonne supplémentaire.\n",
        "\n",
        "Si nous le faisons, les indices pourraient être `0, 1, 2, 3, 4`, ou nous pourrions même utiliser le nom de la barre de chocolat aux deux endroits. C'est une question de préférence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x05dQfMl5vZL"
      },
      "outputs": [],
      "source": [
        "# Index numérique basé sur 0 par défaut, données sous forme de colonne\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'Chocolate bar': ['Skor', 'Heath', 'Snickers', 'Mars', 'Twix'],\n",
        "    'Calories per package': [200, 210, 215, 230, 291],\n",
        "    'Grams per package': [39, 39, 44, 51, 58],\n",
        "    'Deliciousness': [5, 4, 8, 6, 2]\n",
        "})\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xduG3Nx_5vZM"
      },
      "outputs": [],
      "source": [
        "# Mêmes données que l'index et la colonne\n",
        "\n",
        "bars = ['Skor', 'Heath', 'Snickers', 'Mars', 'Twix']\n",
        "df = pd.DataFrame({\n",
        "    'Chocolate bar': bars,\n",
        "    'Calories per package': [200, 210, 215, 230, 291],\n",
        "    'Grams per package': [39, 39, 44, 51, 58],\n",
        "    'Deliciousness': [5, 4, 8, 6, 2]\n",
        "}, index=bars)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEdD8K-J5vZM"
      },
      "source": [
        "## 2. Analyse de données\n",
        "\n",
        "Essayons quelques choses et voyons ce que nous pouvons en tirer.\n",
        "\n",
        "Tout d'abord, afin de faire des choses plus intéressantes, nous voudrons un ensemble de données plus important. Nous utiliserons la fonction `read_csv` de `pandas` pour ouvrir un fichier de valeurs séparées par des virgules (.csv) provenant de GitHub qui contient des données sur la météo telle que mesurée en janvier 2023 à l'aéroport Pearson de Toronto ([source](https://climat.meteo.gc.ca/climate_data/daily_data_f.html?StationID=51459));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WhwyTwiq5vZM"
      },
      "outputs": [],
      "source": [
        "# Lecture à partir d'un fichier CSV distant\n",
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/coding-integration/Science-des-donnees/main/2023-01_51459fr.csv\"\n",
        "df = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfIGbzyd5vZM"
      },
      "source": [
        "*P.S. You can also use your own files for data. If you're using notebooks in an IDE like VSCode, you can just use local files. If you're using Google Colab or Calysto, you can upload files to the instance. Then you would read them using standard I/O functions like this:*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7cBDu3c5vZM"
      },
      "outputs": [],
      "source": [
        "# Lecture à partir d'un fichier CSV local\n",
        "import pandas as pd\n",
        "path = \"2023-01_51459fr\"\n",
        "df = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbizLDHg5vZM"
      },
      "source": [
        "### Visualisation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojGX6FLN5vZM"
      },
      "source": [
        "Avant d'utiliser `print(df)`, nous devons réaliser que cela pourrait être un long fichier. Si nous voulons voir quel type de données il contient, nous n'avons pas besoin de tout regarder - les deux premières lignes devraient suffire.\n",
        "\n",
        "Pour ce faire, nous utilisons `DataFrame.head()` :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOlYJyca5vZM"
      },
      "outputs": [],
      "source": [
        "# Afficher la tête ou les premières lignes d'un DataFrame\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXumu1yk5vZN"
      },
      "source": [
        "Nous pouvons voir que ce `DataFrame` est indexé numériquement et qu'il a 5 colonnes: une date, une température maximale et minimale en degrés Celsius, de la pluie en millimètres et de la neige en centimètres.\n",
        "\n",
        "Tout d'abord, définissons la date comme index. Ce ne sont pas vraiment des données météorologiques; c'est l'étiquette que chaque ligne de données devrait porter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZMeCWVE5vZN"
      },
      "outputs": [],
      "source": [
        "# Changement de la colonne 'date' en index\n",
        "df = df.set_index('Date', drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wE71Nzx95vZN"
      },
      "outputs": [],
      "source": [
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "885dzMv55vZN"
      },
      "source": [
        "Supposons que nous voulons accéder à des données particulières. Vous vous souvenez peut-être de `loc` que nous avons vu plus tôt dans ce tutoriel. Nous pouvons également l'utiliser ici. Je ne me souviens pas si il pleuvait le 8 janvier. Découvrons-le:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "557wXJ1Z5vZN"
      },
      "outputs": [],
      "source": [
        "# Extraction d'une ligne du DataFrame\n",
        "print(df.loc['2023-01-08'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TK53vFPT5vZN"
      },
      "source": [
        "Il ne pleuvait pas. Mais il faisait très froid!\n",
        "\n",
        "**Vérification de compréhension :** Jetez un coup d'œil de plus près à la dernière sortie. Quel type pensez-vous que cela a?\n",
        "\n",
        "<details><summary>Cliquez pour révéler</summary>\n",
        "\n",
        "C'est une `Series` ! Elle a un `dtype` et un `name`, qui est l'en-tête de colonne. Cela peut sembler étrange si vous vous souvenez qu'auparavant, une Series était une colonne d'un `DataFrame`. En d'autres termes, les données ont dû être transposées ici. En effet, les en-têtes de colonnes du `DataFrame` deviennent les indices de ligne !\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHpCPimp5vZN"
      },
      "source": [
        "Que faire si je veux seulement obtenir la température minimale à une certaine date sans toutes les autres données? Je peux obtenir une cellule de données spécifique en utilisant une paire d'indices dans la fonction `loc`, tout comme les coordonnées d'un point."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3xTzjo25vZN"
      },
      "outputs": [],
      "source": [
        "# Extraction d'une seule cellule du DataFrame\n",
        "print(df.loc['2023-01-08', 'Temp. min (C)'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGol5S4v5vZN"
      },
      "source": [
        "Nous pouvons obtenir une seule *colonne* en indexant directement au lieu d'utiliser `loc`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBC1PeYy5vZO"
      },
      "outputs": [],
      "source": [
        "# Extraction d'une colonne de la table\n",
        "print(df['Temp. min (C)'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJNOnJiL5vZO"
      },
      "source": [
        "Remarquez que cela renvoie également une `Series` avec les indices de ligne intacts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jj6dbsB15vZO"
      },
      "source": [
        "Nous pouvons trier les `DataFrame` tout comme nous pouvons trier les `Series` selon les [valeurs](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html) ou les [indices](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_index.html), avec l'étape supplémentaire de spécifier la colonne par laquelle trier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QliQ-HLm5vZO"
      },
      "outputs": [],
      "source": [
        "# Tri d'un DataFrame par colonne\n",
        "print(df.sort_values(by='Temp. min (C)'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3Bp5ndP5vZO"
      },
      "outputs": [],
      "source": [
        "# Tri d'un DataFrame par indices\n",
        "print(df.sort_index())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2Z06h_X5vZO"
      },
      "source": [
        "### Modification\n",
        "\n",
        "Nous ajouterons une colonne à notre `DataFrame`. Nous avons une température maximale et minimale; ajoutons une colonne d'écart entre la température maximale et minimale.\n",
        "\n",
        "C'est là que nous voyons la magie des `Series` que nous avons vue plus tôt! Aucune boucle n'est nécessaire; nous pouvons simplement effectuer une opération sur toute une colonne:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9cJLlug5vZO"
      },
      "outputs": [],
      "source": [
        "# Insérer une nouvelle colonne basée sur deux colonnes existantes\n",
        "écart_series = df['Temp. max (C)'] - df['Temp. min (C)']\n",
        "df['Temp. écart (C)'] = écart_series\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeY3XJ9H5vZO"
      },
      "source": [
        "L'ordre des colonnes peut être réaffecté comme suit :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJYG6sfo5vZO"
      },
      "outputs": [],
      "source": [
        "# Réaffecter l'ordre des colonnes\n",
        "df = df[['Temp. max (C)', 'Temp. min (C)', 'Temp. écart (C)', 'Pluie (mm)', 'Neige (cm)']]\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjynvvfG5vZO"
      },
      "source": [
        "Remarquez comment la neige est en cm mais la pluie est en mm ? Nous allons convertir la neige en mm afin de ne pas perdre de précision.\n",
        "\n",
        "Le problème, c'est qu'il n'a pas du tout neigé les premiers jours de janvier. Toutes les valeurs sont `0.0`. Cela signifie que nous ne pourrons pas vérifier notre calcul. Mais nous pouvons également utiliser la queue `tail` au lieu de la tête `head` pour prévisualiser les derniers jours, qui ont eu de la neige.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FMijnE25vZP"
      },
      "outputs": [],
      "source": [
        "print(df.tail())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-yLa6a45vZP"
      },
      "outputs": [],
      "source": [
        "# Mettre à jour les données d'une colonne\n",
        "df['Neige (cm)'] = df['Neige (cm)'] * 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBnzB8bL5vZP"
      },
      "outputs": [],
      "source": [
        "print(df.tail())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRriNECW5vZP"
      },
      "source": [
        "Cela a bien fonctionné. Nous ferions mieux de mettre à jour l'étiquette de la colonne également."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjxjbGCE5vZP"
      },
      "outputs": [],
      "source": [
        "# Renommer une colonne\n",
        "df = df.rename(columns={'Neige (cm)': 'Neige (mm)'})\n",
        "print(df.tail())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-CcoOnm5vZP"
      },
      "source": [
        "**Vérification de compréhension :** Ajouter une dernière colonne pour les précipitations totales ? Vous n'aurez pas besoin de réorganiser les colonnes car elles viendront déjà après la pluie et la neige."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhkAB38Q5vZP"
      },
      "outputs": [],
      "source": [
        "# Ajouter une colonne pour les précipitations totales\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TALw8reN5vZP"
      },
      "source": [
        "<details>\n",
        "<summary>Cliquez pour révéler</summary>\n",
        "\n",
        "```\n",
        "pt_series = df['Neige (mm)'] + df['Pluie (mm)']\n",
        "df['Précipitations totales (mm)'] = pt_series\n",
        "print(df.tail())\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NLMxJoB5vZP"
      },
      "source": [
        "### Analyse\n",
        "\n",
        "Commençons à analyser un peu ces données. Vous pourriez imprimer l'intégralité du DataFrame et l'inspecter une ligne à la fois, mais cela ne nous permet pas d'avoir une idée des tendances dans les données.\n",
        "\n",
        "Nous essayons de faire une chose importante: **identifier des choses intéressantes que nous pourrions vouloir examiner plus en détail**. En d'autres termes, nous voulons poser des questions sur ces données.\n",
        "\n",
        "Nous pouvons commencer à poser quelques questions basées sur l'intuition telles que:\n",
        "\n",
        "\n",
        "*  Il neige beaucoup en janvier.\n",
        "\n",
        "*  Janvier est très froid.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbQjmG2y5vZQ"
      },
      "source": [
        "#### Est-ce qu'il neige plus qu'il ne pleut ?\n",
        "Cela devrait être assez simple; nous allons totaliser les quantités de précipitations de pluie et de neige et voir laquelle est plus grande.\n",
        "\n",
        "Pour ce faire, nous pouvons additionner chaque `Series` et les comparer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHA8-D_O5vZQ"
      },
      "outputs": [],
      "source": [
        "# Somme d'une série\n",
        "pluie_totale = df['Pluie (mm)'].sum()\n",
        "neige_totale = df['Neige (mm)'].sum()\n",
        "\n",
        "print(f'Pluie totale: {pluie_totale:>5} mm')\n",
        "print(f'Neige totale: {neige_totale:>5} mm')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycMSkAZF5vZQ"
      },
      "source": [
        "Il y a presque 9 fois plus de neige que de pluie ! Je me demande combien de *jours* de plus il neige que de pluie ?\n",
        "\n",
        "Pour le savoir, nous pouvons filtrer le `DataFrame` en fonction du fait que la valeur de la colonne concernée est supérieure à `0`. Cela nous présente une fonctionnalité puissante de `Series` : appliquer une opération booléenne à chaque élément en une seule passe.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cu78so-o5vZQ"
      },
      "outputs": [],
      "source": [
        "# Filtrer un DataFrame\n",
        "jours_de_pluie = df[df['Pluie (mm)'] > 0]\n",
        "jours_de_neige = df[df['Neige (mm)'] > 0]\n",
        "\n",
        "# Dans DataFrames, la taille fait référence aux deux dimensions.\n",
        "# Pour obtenir uniquement le nombre de lignes, obtenez la forme (shape) de la première colonne.\n",
        "n_jours_de_pluie = jours_de_pluie.shape[0]\n",
        "n_jours_de_neige = jours_de_neige.shape[0]\n",
        "\n",
        "print(f'Jours de pluie: {n_jours_de_pluie:>2}')\n",
        "print(f'Jours de neige: {n_jours_de_neige:>2}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8LJotff5vZQ"
      },
      "source": [
        "C'est surprenant ! Même s'il y avait beaucoup plus de neige que de pluie, il y avait presque autant de jours de pluie que de neige. Cela soulève des questions intéressantes que nous pourrions poursuivre pour une compréhension plus approfondie.\n",
        "\n",
        "Avant de poser une question différente, vérifions un autre facteur. J'ai remarqué lorsque nous avons regardé la `tail` du `DataFrame` que certains jours avaient à la fois de la neige * et * de la pluie. Combien y en avait-il ?\n",
        "\n",
        "Nous pouvons filtrer comme avant, et nous pouvons utiliser la logique pour combiner les conditions (la neige et la pluie sont au-dessus de `0`). Dans `pandas`, nous utiliserons des opérateurs légèrement différents lorsque nous essaierons de combiner plusieurs conditions sur des éléments individuels :\n",
        "\n",
        "| Opération | Python normal | pandas |\n",
        "| --- | --- | --- |\n",
        "| les deux doivent être vrais | `and` | `&` |\n",
        "| au moins un doit être vrai | `or` | `\\|` |\n",
        "| doit être faux | `not` | `~` |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgjWNpMR5vZQ"
      },
      "outputs": [],
      "source": [
        "# Filtrage pour les jours où il a plu et neigé\n",
        "les_deux_jours = df[(df['Pluie (mm)'] > 0) & (df['Neige (mm)'] > 0)]\n",
        "n_les_deux_jours = df.shape[0]\n",
        "\n",
        "print(f'Les jours où il neigeait et pleuvait: {n_jours_de_pluie:>2}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_04rsvb5vZQ"
      },
      "source": [
        "Est-ce que ça a du sens ? Ou avez-vous besoin de plus d'informations?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znujyfSh5vZQ"
      },
      "source": [
        "#### Quel est le froid de janvier ?\n",
        "\n",
        "Un moyen simple de déterminer à quel point il faisait froid en janvier consiste à faire la moyenne des températures maximales et minimales sur l'ensemble du mois. Nous pouvons le faire en isolant les `Series` respectives et en utilisant `mean` (moyen)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAF0KjY15vZQ"
      },
      "outputs": [],
      "source": [
        "# Température minimale moyenne\n",
        "print(df['Temp. min (C)'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2CT25ro5vZQ"
      },
      "outputs": [],
      "source": [
        "# Température maximale moyenne\n",
        "print(df['Temp. max (C)'].mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2Fc0hbg5vZR"
      },
      "source": [
        "Nous allons définir une fonction pour obtenir le moyen, la médiane, la plage et le mode à la fois pour les températures maximales et minimales.\n",
        "\n",
        "Le mode est un peu plus complexe puisque (1) il faut d'abord arrondir, et (2) il peut y avoir plus d'un mode, donc il faut prévoir une liste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "N0y2bfwH5vZR"
      },
      "outputs": [],
      "source": [
        "# Fonction pour afficher les quatre moyennes\n",
        "def afficher_moyennes(s: pd.Series, word: str) -> None:\n",
        "    s_moyenne = s.mean()\n",
        "    s_médiane = s.median()\n",
        "    s_plage = s.max() - s.min()\n",
        "    s_modes = s.round(0).mode().values\n",
        "\n",
        "    print(f'{word} moyenne:\\t{s_moyenne}')\n",
        "    print(f'{word} médiane:\\t{s_médiane}')\n",
        "    print(f'{word} plage:\\t{s_plage}')\n",
        "    print(f'{word} mode(s):\\t{s_modes}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmQzKlFm5vZR"
      },
      "outputs": [],
      "source": [
        "# Les moyennes des températures minimales\n",
        "afficher_moyennes(df['Temp. min (C)'], 'Température minimale')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Om4Mb6305vZR"
      },
      "outputs": [],
      "source": [
        "# Les moyennes des températures maximales\n",
        "afficher_moyennes(df['Temp. max (C)'], 'Température maximale')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUx71EU65vZR"
      },
      "source": [
        "Chaque moyenne raconte une histoire légèrement différente. Nous remarquons que la moyenne et la médiane pour les températures minimales sont beaucoup plus proches du mode, ce qui suggère une cohérence : lors d'une journée typique en janvier, la température est descendue à environ -3 degrés Celsius. Mais la température maximale avait beaucoup de jours qui étaient 2-3 degrés plus chauds que la moyenne.\n",
        "\n",
        "Nous remarquons également qu'il y a une grande plage pour les températures maximales et minimales. Cela suggère qu'il y avait au moins une journée très chaude ou très froide en janvier. Devrions-nous retirer les valeurs aberrantes pour que notre image de la moyenne soit plus précise ?\n",
        "\n",
        "Nous examinerons deux façons de retirer les valeurs aberrantes. Mais d'abord, afin de rendre ces données plus intéressantes, nous allons passer à un ensemble de données avec l'ensemble complet des données de 2022 pour nous assurer que notre taille d'échantillon est suffisante.\n",
        "\n",
        "Exécutez le prochain bloc de code pour charger un gros ensemble de données et effectuer les mises à jour que nous avons faites plus tôt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Pl1ZZodJ5vZR"
      },
      "outputs": [],
      "source": [
        "# charger un gros ensemble de données et effectuer des mises à jour\n",
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/coding-integration/Science-des-donnees/main/2022_51459fr.csv\"\n",
        "df_gros = pd.read_csv(url)\n",
        "df_gros = df_gros[['Temp. max (C)', 'Temp. min (C)', 'Pluie (mm)', 'Neige (cm)']]\n",
        "df_gros['Neige (cm)'] = df_gros['Neige (cm)'] * 10\n",
        "df_gros = df_gros.rename(columns={'Neige (cm)': 'Neige (mm)'})\n",
        "df_gros['Précipitations totales (mm)'] = df_gros['Pluie (mm)'] + df_gros['Neige (mm)']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNHEv3qJ5vZR"
      },
      "source": [
        "#### Les valeurs aberrantes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHsAxpNh5vZR"
      },
      "source": [
        "Tout d'abord, nous pourrions profiter de la méthode 'Series.quantile', qui prend un décimal représentant un pourcentage et renvoie la valeur de coupure pour ce quantile :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "-92_AEoT5vZS"
      },
      "outputs": [],
      "source": [
        "# Fonction pour supprimer les 10 % (quantiles) supérieurs et inférieurs\n",
        "def supprimer_valeurs_aberrantes_quantile(s: pd.Series) -> pd.Series:\n",
        "    # Déterminer les valeurs du 90ème et du 10ème quantiles\n",
        "    q_superieur = s.quantile(0.9)\n",
        "    q_inferieur = s.quantile(0.1)\n",
        "\n",
        "    # Créer une autre série en filtrant les éléments qui sont entre les bornes supérieure et inférieure\n",
        "    return s[(s < q_superieur) & (s > q_inferieur)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diWkE7k65vZS"
      },
      "source": [
        "Deuxièmement, nous pourrions profiter de la méthode `Series.std`, qui renvoie l'écart type (distance moyenne entre un point de données et la moyenne). Nous pourrions ensuite couper les points de données qui sont plus éloignés que `n` écarts types de la moyenne :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "LU-uz2sH5vZS"
      },
      "outputs": [],
      "source": [
        "# Fonction pour supprimer les valeurs en dehors de 'n' écart-types\n",
        "def supprimer_valeurs_aberrantes_std(s: pd.Series, max_ecarts: float) -> pd.Series:\n",
        "    # Déterminer les bornes comme un multiple d'écart type   \n",
        "    max_distance = s.std() * max_ecarts\n",
        "\n",
        "    # Créer une autre série en filtrant les éléments qui sont entre les bornes supérieure et inférieure\n",
        "    moyenne = s.mean()\n",
        "    return s[(s < (moyenne + max_distance)) & (s > (moyenne - max_distance))]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXoI_s0B5vZS"
      },
      "source": [
        "Utilisons la méthode d'écart type et voyons comment cela modifie les moyennes :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpOuSKiI5vZS"
      },
      "outputs": [],
      "source": [
        "# Les moyennes des températures minimales sans aberrantes\n",
        "temp_min_sans_aberrantes = supprimer_valeurs_aberrantes_std(df_gros['Temp. min (C)'], 1)\n",
        "afficher_moyennes(temp_min_sans_aberrantes, 'Température minimale')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRsGXuB15vZS"
      },
      "outputs": [],
      "source": [
        "# Les moyennes des températures maximales sans aberrantes\n",
        "temp_max_sans_aberrantes = supprimer_valeurs_aberrantes_std(df_gros['Temp. max (C)'], 1)\n",
        "afficher_moyennes(temp_max_sans_aberrantes, 'Température maximale')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncU-G26E5vZS"
      },
      "source": [
        "Nous remarquons que la moyenne de la température minimale n'est plus aussi froide qu'avant (les modes ne comprennent plus 2 degrés positifs). Cela suggère que janvier a connu un nombre significatif de journées chaudes où la température oscillait entre 2 et 4 degrés Celsius environ. Bien sûr, ce n'est pas encore une conclusion; c'est simplement une direction à examiner de plus près."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raYLKVwi5vZS"
      },
      "source": [
        "#### Les Corrélations\n",
        "\n",
        "Nous pourrions avoir d'autres idées intuitives à propos de janvier, par exemple, peut-être que vous croyez qu'il neige généralement si la température reste à 0 ou en dessous, mais qu'il pleut si la température reste au-dessus de 0. Voyons cela!\n",
        "\n",
        "Une façon de le faire est de vérifier la **corrélation**, qui est une caractéristique de la `Series`. Une corrélation varie de `-1` (les deux événements se produisent à des moments opposés) à `1` (les deux événements coïncident toujours).\n",
        "\n",
        "Tout d'abord, nous allons binariser l'une des colonnes: nous prendrons notre quantité de neige et la transformerons en Vrai/Faux (*True/False*) pour représenter s'il a neigé ou non. Cela nous donne une variable continue (température maximale quotidienne) et une variable binaire (neige). Cela signifie que nous faisons essentiellement une [régression logistique](https://fr.wikipedia.org/wiki/R%C3%A9gression_logistique), où la température sera traitée comme un prédicteur de s'il a neigé."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_FTfzk55vZS"
      },
      "outputs": [],
      "source": [
        "# Ajouter une nouvelle colonne\n",
        "df_gros['Est-ce qu il a neigé ?'] = df_gros['Neige (mm)'] > 0\n",
        "print(df_gros.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjNQrjup5vZS"
      },
      "outputs": [],
      "source": [
        "# Vérifier la corrélation\n",
        "corr = df_gros['Est-ce qu il a neigé ?'].corr(df_gros['Temp. min (C)'])\n",
        "print(corr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn1KO6Ew5vZT"
      },
      "source": [
        "Nous obtenons une corrélation négative décente. Cela signifie qu'il a tendance à neiger lorsque la température est plus basse, ce à quoi nous nous attendons.\n",
        "\n",
        "Cependant, cette corrélation pourrait être plus forte. Considérez qu'il doit y avoir beaucoup de jours où il ne neige ni ne pleut, et nous ne voulons pas les compter: nous savons que le fait d'être froid ne cause pas précipitation! Alors commençons à nouveau, mais d'abord, nous allons filtrer pour les jours qui ont eu de la précipitation. Nous pouvons filtrer notre `DataFrame` en utilisant la colonne `Précipitations Totales (mm)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6aibQ1T5vZT"
      },
      "outputs": [],
      "source": [
        "# Créer un sous-ensemble plus logique\n",
        "df_gros_avec_précipitation = df_big[df_big['Précipitations totales (mm)'] > 0].copy()\n",
        "df_gros_avec_précipitation['Est-ce qu il a neigé ?'] = df_gros_avec_précipitation['Neige (mm)'] > 0\n",
        "\n",
        "print(df_gros_avec_précipitation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wv7s9FVR5vZT"
      },
      "outputs": [],
      "source": [
        "# Refaire la corrélation\n",
        "corr = df_gros_avec_précipitation['Est-ce qu il a neigé ?'].corr(df_gros_avec_précipitation['Temp. min (C)'])\n",
        "print(corr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ys715Jni5vZT"
      },
      "source": [
        "Maintenant, il y a une corrélation négative qui est 50% plus forte. C'est un bon signe et cela correspond à nos intuitions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDpdFg7T5vZT"
      },
      "source": [
        "**Vérification de compréhension :**  Pouvez-vous tester la corrélation inverse : est-ce que la pluie peut être prédite par une température élevée? (Vous devriez trouver une corrélation positive entre la température et la pluie.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_Tx15Ow5vZT"
      },
      "outputs": [],
      "source": [
        "# Vérifiez la corrélation \"pluvieux les jours chauds\"\n",
        "# À FAIRE AJOUTER VOTRE CODE ICI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2v18a00a5vZT"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUmP2Y_C5vZT"
      },
      "source": [
        "Nous avons acquis beaucoup d'outils tout au long de ce notebook. En particulier, nous avons appris:\n",
        "\n",
        "* Ce qu'est une `Series` : une donnée linéaire qui peut avoir des étiquettes\n",
        "* Ce qu'est un `DataFrame` : une table où chaque colonne est une `Series`\n",
        "* Comment visualiser, trier, filtrer et modifier ces structures de données\n",
        "* Comment calculer des statistiques de base sur les données\n",
        "* Comment manipuler les données pour les mettre dans une forme où nous pouvons commencer à utiliser des statistiques pour répondre à des questions\n",
        "\n",
        "Dans le dernier partie de cette série, nous mettrons ces compétences en pratique avec des techniques de recherche et de nettoyage de données pour répondre à une question du monde réel plus complexe.\n",
        "\n",
        "À bientôt!\n",
        "\n",
        "\n",
        "![Panda waving goodbye](https://raw.githubusercontent.com/unfamiliarplace/acse-integration/main/data_science/assets/panda_wave.jpg)\n",
        "<sub>*Panda image from [VCG Photo](https://news.cgtn.com/news/3d3d414e32557a4e30457a6333566d54/share_p.html)*</sub>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "458dd1d06817a72759ca62d766d5a1c58019d69edba750c2eb07d80bb7630974"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}